{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1DxBBFXXdkLRRCMomSKbrNohlsIfz2d2Q",
      "authorship_tag": "ABX9TyNZSaWG4L8bHUBsYk2hLsXG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucaznguyen/understand-cl/blob/main/Toward_CF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "HuijmSG6-HAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.applications import inception_v3, vgg16\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from tensorflow.keras.layers import Input, InputLayer, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Flatten, Dense, Dropout, BatchNormalization, AveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import keras\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10, mnist\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "AMTQnTjJ-e4Y"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount drive"
      ],
      "metadata": {
        "id": "8wVzBPEz-M7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Paper/Toward Understand CF/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyKl5E7Cusfi",
        "outputId": "995485e0-39f2-4607-ddd9-e5e89d883cfe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Paper/Toward Understand CF/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import data"
      ],
      "metadata": {
        "id": "RglK9TnS-OUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Rot-MNIST"
      ],
      "metadata": {
        "id": "5sxHS2lHCrag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid = np.loadtxt('mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat')"
      ],
      "metadata": {
        "id": "aTzuyffc-kNS"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for data in train_valid:\n",
        "  y.append(int(data[-1]))\n",
        "  X.append(data[:-1])"
      ],
      "metadata": {
        "id": "gH1gAQ42x8ld"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X[0].reshape(28, 28))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "r0r0geciyeO3",
        "outputId": "9d4250d4-7d9b-4006-bd8b-8f8d1be91ee4"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST"
      ],
      "metadata": {
        "id": "remV4ETZCvTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X, y), (X_test, y_test_raw) = mnist.load_data()\n",
        "assert X.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y.shape == (60000,)\n",
        "assert y_test_raw.shape == (10000,)"
      ],
      "metadata": {
        "id": "YYTd00NOCLPl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_flatten = []\n",
        "for data in X:\n",
        "  X_flatten.append(data.reshape(784))\n",
        "\n",
        "X = X_flatten\n",
        "\n",
        "X_flatten = []\n",
        "for data in X_test:\n",
        "  X_flatten.append(data.reshape(784))\n",
        "\n",
        "X_test = X_flatten"
      ],
      "metadata": {
        "id": "s5yEvzC8CluV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train_raw, y_val_raw = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NteYkYffzp_G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)"
      ],
      "metadata": {
        "id": "_h94_u-r3Wc7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train_raw, num_classes=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val_raw, num_classes=10)\n",
        "print('y_train.shape', y_train.shape)\n",
        "print(y_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyTmnriL19lC",
        "outputId": "2fc49ec7-0a87-4cd0-9034-834f8901ac95"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train.shape (48000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.loadtxt('mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat')"
      ],
      "metadata": {
        "id": "Bu9A9-K-1PVj"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "y_test_raw = []\n",
        "\n",
        "for data in test:\n",
        "  y_test_raw.append(int(data[-1]))\n",
        "  X_test.append(data[:-1])\n",
        "\n",
        "y_test = tf.keras.utils.to_categorical(y_test_raw, num_classes=10)"
      ],
      "metadata": {
        "id": "xbVswV1F1UaG"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(X_test)"
      ],
      "metadata": {
        "id": "2agde4iI4L8b"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create MLP Backbone"
      ],
      "metadata": {
        "id": "ucFniIn7k94i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Dense(784, activation='relu')(inputs)\n",
        "    X = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    outputs = Dense(10, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    #for layer in pretrained_model.layers: \n",
        "    #    layer.trainable = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "evwOojtfzpEy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Transfer_model():\n",
        "\n",
        "    #pretrained_model  = keras_efficientnet_v2.EfficientNetV2M(dropout=1e-6, num_classes=0,pretrained=\"imagenet\",include_preprocessing=True)\n",
        "    pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False)\n",
        "    pretrained_model.trainable = False\n",
        "    last_output = pretrained_model.output\n",
        "    x = Flatten(x)\n",
        "    x = Dense(784, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    outputs = Dense(10, activation='softmax')(x)\n",
        "    model = Model(inputs=pretrained_model.input, outputs=outputs)\n",
        "    #for layer in pretrained_model.layers: \n",
        "    #    layer.trainable = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "ObeCCBH3OEm9"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define some functions"
      ],
      "metadata": {
        "id": "3qYmM3BDlA2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_data(X, y, batch_size):\n",
        "  import random\n",
        "\n",
        "  batch_index = []\n",
        "  for i in range(batch_size):\n",
        "    n = random.randint(0, len(X)-1)\n",
        "    batch_index.append(n)\n",
        "  return X[batch_index], y[batch_index]"
      ],
      "metadata": {
        "id": "9GwiGGyb8bJA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reservoir(buffer, buffer_size, X, y, z):\n",
        "  import random\n",
        "\n",
        "  X_list = []\n",
        "  y_list = []\n",
        "  z_list = []\n",
        "  if len(buffer) > 0:\n",
        "    X_list = list(buffer[0])\n",
        "  for data in X:\n",
        "    X_list.append(data)\n",
        "\n",
        "  if len(buffer) > 0:\n",
        "    y_list = list(buffer[1])\n",
        "  for data in y:\n",
        "    y_list.append(data)\n",
        "\n",
        "  if len(buffer) > 0:\n",
        "    z_list = list(buffer[2])\n",
        "  for data in y:\n",
        "    z_list.append(data)\n",
        "\n",
        "  list_index = []\n",
        "\n",
        "  n = len(X_list)\n",
        "\n",
        "  for i in range(n):\n",
        "    list_index.append(i)\n",
        "\n",
        "  res = [0]*buffer_size\n",
        "  for i in range(buffer_size):\n",
        "      res[i] = list_index[i]\n",
        "\n",
        "  for i in range(n):\n",
        "    j = random.randrange(i + 1)\n",
        "    if(j < buffer_size):\n",
        "        res[j] = list_index[i]\n",
        "    i = i + 1\n",
        "\n",
        "  return [np.array(X_list)[res], np.array(y_list)[res], np.array(z_list)[res]]"
      ],
      "metadata": {
        "id": "aGA3M6ZpTQwr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reservoir(buffer, buffer_size, X, y, z):\n",
        "  import random\n",
        "\n",
        "  X_list = []\n",
        "  y_list = []\n",
        "  z_list = []\n",
        "  if len(buffer) > 0:\n",
        "    X_list = list(buffer[0])\n",
        "  for data in X:\n",
        "    X_list.append(data)\n",
        "\n",
        "  if len(buffer) > 0:\n",
        "    y_list = list(buffer[1])\n",
        "  for data in y:\n",
        "    y_list.append(data)\n",
        "\n",
        "  if len(buffer) > 0:\n",
        "    z_list = list(buffer[2])\n",
        "  for data in z:\n",
        "    z_list.append(data)\n",
        "\n",
        "  list_index = []\n",
        "\n",
        "  n = len(X_list)\n",
        "\n",
        "  for i in range(n):\n",
        "    list_index.append(i)\n",
        "\n",
        "  res = [0]*buffer_size\n",
        "  for i in range(buffer_size):\n",
        "      res[i] = list_index[i]\n",
        "\n",
        "  for i in range(n):\n",
        "    j = random.randrange(i + 1)\n",
        "    if(j < buffer_size):\n",
        "        res[j] = list_index[i]\n",
        "    i = i + 1\n",
        "\n",
        "  return [np.array(X_list)[res], np.array(y_list)[res], np.array(z_list)[res]]"
      ],
      "metadata": {
        "id": "PSdBcPknUjEH"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_reservoir(num_seen, buffer_size):\n",
        "  if num_seen < buffer_size:\n",
        "      return num_seen\n",
        "\n",
        "  rand = np.random.randint(0, num_seen + 1)\n",
        "  # print(rand)\n",
        "  if rand < buffer_size:\n",
        "      return rand\n",
        "  else:\n",
        "      return -1"
      ],
      "metadata": {
        "id": "2Cl14UidQxtf"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_seen = 0\n",
        "\n",
        "for i in range(300):\n",
        "  print(check_reservoir(num_seen, 200))\n",
        "  num_seen = num_seen + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKx-XjQLSvn0",
        "outputId": "55379cba-ac16-4ae8-a6a3-cea3a4249a9a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "134\n",
            "182\n",
            "174\n",
            "160\n",
            "199\n",
            "199\n",
            "107\n",
            "192\n",
            "66\n",
            "55\n",
            "74\n",
            "110\n",
            "147\n",
            "153\n",
            "15\n",
            "-1\n",
            "41\n",
            "53\n",
            "15\n",
            "-1\n",
            "91\n",
            "150\n",
            "134\n",
            "30\n",
            "139\n",
            "49\n",
            "103\n",
            "14\n",
            "98\n",
            "93\n",
            "149\n",
            "7\n",
            "49\n",
            "185\n",
            "62\n",
            "44\n",
            "73\n",
            "-1\n",
            "195\n",
            "-1\n",
            "152\n",
            "18\n",
            "123\n",
            "111\n",
            "43\n",
            "30\n",
            "64\n",
            "22\n",
            "52\n",
            "-1\n",
            "143\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "56\n",
            "51\n",
            "84\n",
            "56\n",
            "49\n",
            "-1\n",
            "79\n",
            "163\n",
            "173\n",
            "-1\n",
            "145\n",
            "11\n",
            "44\n",
            "58\n",
            "162\n",
            "-1\n",
            "92\n",
            "136\n",
            "-1\n",
            "-1\n",
            "56\n",
            "146\n",
            "67\n",
            "121\n",
            "194\n",
            "91\n",
            "198\n",
            "38\n",
            "-1\n",
            "-1\n",
            "-1\n",
            "68\n",
            "137\n",
            "129\n",
            "37\n",
            "143\n",
            "26\n",
            "72\n",
            "91\n",
            "7\n",
            "110\n",
            "191\n",
            "48\n",
            "198\n",
            "124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Empirical predict"
      ],
      "metadata": {
        "id": "RujB1iPxres9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def empirical_predict(model, X, y):\n",
        "  acc = 0\n",
        "  prob = model(X)\n",
        "\n",
        "  # return 0\n",
        "\n",
        "  n = len(prob)\n",
        "  for i in range(n):\n",
        "    label = list(prob[i]).index(max(list(prob[i])))\n",
        "    if label == y[i]:\n",
        "      acc = acc + 1\n",
        "  return acc/n"
      ],
      "metadata": {
        "id": "WTiLmDGTcGE_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LEEP(y_train, feature_extract):\n",
        "  import math\n",
        "  sum = 0\n",
        "  n = len(y_train)\n",
        "  n_z = len(feature_extract[0])\n",
        "  p_yz = init_zero_2d_arr(n_z, 10)\n",
        "  # print(len(p_yz))\n",
        "  p_z = init_zero_1d_arr(n_z)\n",
        "  for z in range(n_z):\n",
        "    for i in range(n):\n",
        "      # print(\"i\",i)\n",
        "      # print(\"z\",z)\n",
        "      # print(y_train[i][0])\n",
        "      p_yz[z][y_train[i]]=p_yz[z][y_train[i]]+feature_extract[i][z]/n\n",
        "      p_z[z] = p_z[z]+feature_extract[i][z]/n\n",
        "\n",
        "  for i in range(n):\n",
        "    # print(i)\n",
        "    sum_log = 0\n",
        "    for z in range(n_z):\n",
        "      # sum_log = sum_log + p_yz[y_train[i]][z]/p_z[z]*prob_conditional(i, y_train, z, feature_extract)*feature_extract[i][z]\n",
        "      sum_log = sum_log + p_yz[z][y_train[i]]/p_z[z]*feature_extract[i][z]\n",
        "    sum = sum + math.log(sum_log)/n\n",
        "  sum = sum\n",
        "  return sum"
      ],
      "metadata": {
        "id": "fXApKluW-z3F"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check model and functions"
      ],
      "metadata": {
        "id": "3hlEPmbNlTpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP_model(input_shape=len(X[0]))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.SGD()\n",
        "\n",
        "batch_size = 128#len(X_train)\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "buffer_size = 200\n",
        "\n",
        "alpha  = 0.5\n",
        "\n",
        "lr = 0.2\n",
        "\n",
        "buffer = []\n",
        "\n",
        "# Iterate over the batches of a dataset.\n",
        "for i in range(epochs):\n",
        "    iterations = len(X_train)//batch_size\n",
        "    for j in range(iterations):\n",
        "      if len(buffer) > 0:\n",
        "        X_buffer, y_buffer, z_buffer = buffer[0], buffer[1], buffer[2]\n",
        "        X_buffer_batch, y_buffer_batch = batch_data(X_buffer, y_buffer, batch_size)\n",
        "        reg = np.linalg.norm(z_buffer-model(X_buffer))\n",
        "      else:\n",
        "        reg = 0\n",
        "      X_batch, y_batch = batch_data(X_train, y_train, batch_size)\n",
        "      with tf.GradientTape() as tape:\n",
        "          # get_logits = Model(inputs=model.input,\n",
        "          #                        outputs=model.get_layer(model.layers[-2].name).output)\n",
        "          # z_batch = get_logits(X_batch)\n",
        "          logits = model(X_batch)\n",
        "          # Compute the loss value for this batch.\n",
        "          loss_value = lr*loss_fn(y_batch, logits) #+ alpha*reg\n",
        "\n",
        "      # Update the weights of the model to minimize the loss value.\n",
        "      gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "      # buffer = reservoir(buffer, buffer_size, X_batch, y_batch, z_batch)\n",
        "    # print(len(buffer))\n",
        "    # print(\"epoch:\", i, \"loss:\", loss_value, \"acc:\", empirical_predict(model, X_val, y_val_raw))\n",
        "\n",
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5yXajLD6ko-",
        "outputId": "013140c9-23a0-46fe-b5bf-b2e3ae5183f4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4482 - accuracy: 0.8779\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.44818463921546936, 0.877916693687439]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9kx5LnMEGps",
        "outputId": "c212b83c-4d54-40c8-a2af-ac3124492f61"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48000"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(np.array([1, 2])-np.array([3, 4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9lrIMHpOCn2",
        "outputId": "1026fe14-0967-4bd8-c7c0-753da653d859"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8284271247461903"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "881l_hG-9uee",
        "outputId": "48e44675-e688-486e-f77c-14203abe12ed"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50000, 10), dtype=float32, numpy=\n",
              "array([[3.9795211e-01, 1.7102645e-04, 2.4633227e-01, ..., 6.6548742e-02,\n",
              "        2.7387010e-02, 1.4115053e-02],\n",
              "       [7.2294194e-01, 5.8861752e-07, 1.9817117e-01, ..., 2.8166061e-03,\n",
              "        4.6425276e-03, 2.2170534e-04],\n",
              "       [2.8577599e-01, 1.9321065e-05, 1.9883229e-01, ..., 1.9709501e-01,\n",
              "        1.6079638e-02, 1.8943820e-02],\n",
              "       ...,\n",
              "       [9.6338633e-03, 4.9477781e-05, 2.2330265e-02, ..., 4.5664439e-01,\n",
              "        7.9630846e-03, 1.7099804e-01],\n",
              "       [2.3193299e-03, 5.4292206e-04, 1.8454993e-02, ..., 5.8339026e-02,\n",
              "        3.0026104e-02, 4.3316597e-01],\n",
              "       [3.3458009e-02, 1.4445331e-04, 3.1623367e-02, ..., 4.7755054e-01,\n",
              "        1.3066890e-02, 1.4794989e-01]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP_model(input_shape=len(X[0]))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs=1\n",
        "\n",
        "history = model.fit(\n",
        "  x=X_train,\n",
        "  y=y_train,\n",
        "  batch_size=10,\n",
        "  validation_data=(X_test, y_test), \n",
        "  # train_ds,\n",
        "  # validation_data=val_ds,\n",
        "  epochs=epochs, \n",
        "  # callbacks=[MC]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADSshSfu1aKP",
        "outputId": "77a9110d-093e-4a03-f6a4-b9b71b5c0b78"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "960/960 [==============================] - 6s 6ms/step - loss: 1.9144 - accuracy: 0.3092 - val_loss: 1.4374 - val_accuracy: 0.5004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vobEyq6c-O55",
        "outputId": "a5753f6d-8d5e-4497-a947-d91d65d7f422"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50000, 10), dtype=float32, numpy=\n",
              "array([[5.1303023e-01, 1.0745070e-03, 9.1011807e-02, ..., 8.1859261e-02,\n",
              "        2.7702602e-02, 2.7623925e-02],\n",
              "       [8.9694059e-01, 1.7658775e-05, 5.5200361e-02, ..., 5.6980941e-03,\n",
              "        4.8119253e-03, 5.7830114e-04],\n",
              "       [2.3786604e-01, 2.9438184e-04, 6.6927485e-02, ..., 2.8218746e-01,\n",
              "        7.1542193e-03, 4.5566607e-02],\n",
              "       ...,\n",
              "       [5.4793381e-03, 4.3462752e-04, 1.6038278e-02, ..., 3.7326452e-01,\n",
              "        4.8098788e-03, 1.9639176e-01],\n",
              "       [1.4940993e-02, 2.8514990e-03, 4.2365465e-02, ..., 1.1830009e-01,\n",
              "        5.7186630e-02, 1.6145900e-01],\n",
              "       [2.8890099e-02, 1.8374528e-03, 3.2292109e-02, ..., 4.2044598e-01,\n",
              "        1.1044991e-02, 1.5753406e-01]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LLxsReb4F2U",
        "outputId": "b599800c-ad3d-4799-d03b-e933032a64e4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5944 - accuracy: 0.8628\n",
            "0.8628399968147278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup experiment"
      ],
      "metadata": {
        "id": "qMSXfZ7x-yTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_zero_2d_arr(m, n):\n",
        "  arr = []\n",
        "  for i in range(m):\n",
        "    ar = []\n",
        "    for j in range(n):\n",
        "      ar.append(0)\n",
        "    arr.append(ar)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "JCRO16Ra_kHf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_zero_1d_arr(n):\n",
        "  arr = []\n",
        "  for i in range(n):\n",
        "    arr.append(0)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "Mij24Rhk_mQw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameter"
      ],
      "metadata": {
        "id": "tfYOAAMRml0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SEQUENCE = 1\n",
        "NUM_TASK = 5\n",
        "NUM_CLASS = 3\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "alpha = 0.3\n",
        "beta = 0.5\n",
        "\n",
        "lr = 0.03\n",
        "\n",
        "buffer_size = 200"
      ],
      "metadata": {
        "id": "tC-I7pki_1VM"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run tasks"
      ],
      "metadata": {
        "id": "Q3YuxC2umn6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "LEEP_score = []\n",
        "\n",
        "buffer = []\n",
        "\n",
        "task_list = []\n",
        "\n",
        "acc_task_list = []\n",
        "\n",
        "model = MLP_model(input_shape=len(X[0]))\n",
        "\n",
        "for t in range(NUM_TASK):\n",
        "  print(\"TASK:\", t)\n",
        "  #pick class\n",
        "  pick_class = [random.randint(0, 7)]\n",
        "  count = 0\n",
        "  while count < NUM_CLASS:\n",
        "    count =  count + 1\n",
        "    pick_class.append(pick_class[0]+count)\n",
        "  \n",
        "  #pick data train\n",
        "  X_train_choice = []\n",
        "  y_train_choice = []\n",
        "  for i in range(len(X)):\n",
        "    if y[i] in pick_class:\n",
        "      X_train_choice.append(X[i])\n",
        "      y_train_choice.append(y[i])\n",
        "  \n",
        "  #pick data test\n",
        "  X_test_choice = []\n",
        "  y_test_choice = []\n",
        "  for i in range(len(X_test)):\n",
        "    if y_test_raw[i] in pick_class:\n",
        "      X_test_choice.append(X_test[i])\n",
        "      y_test_choice.append(y_test_raw[i])\n",
        "\n",
        "  task_list.append([X_train_choice, X_test_choice, y_train_choice, y_test_choice])\n",
        "\n",
        "  X_train_choice = np.array(X_train_choice)\n",
        "  y_train_choice =  tf.keras.utils.to_categorical(y_train_choice, num_classes = 10)\n",
        "\n",
        "  X_test_choice = np.array(X_test_choice)\n",
        "  # y_test_choice =  tf.keras.utils.to_categorical(y_test_choice, num_classes = 10)\n",
        "\n",
        "  loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  optimizer = tf.keras.optimizers.SGD()\n",
        "\n",
        "  for i in range(epochs):\n",
        "      iterations = len(X_train_choice)//batch_size\n",
        "      for j in range(iterations):\n",
        "        if len(buffer) > 0:\n",
        "          X_buffer, y_buffer, z_buffer = buffer[0], buffer[1], buffer[2]\n",
        "          X_buffer_batch, y_buffer_batch = batch_data(X_buffer, y_buffer, batch_size)\n",
        "          reg = np.linalg.norm(z_buffer-model(X_buffer))\n",
        "        else:\n",
        "          reg = 0\n",
        "        X_batch, y_batch = batch_data(X_train_choice, y_train_choice, batch_size)\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_batch = get_logits(X_batch)\n",
        "            logits = model(X_batch)\n",
        "            # Compute the loss value for this batch.\n",
        "            loss_value = loss_fn(y_batch, logits) + alpha*reg\n",
        "\n",
        "        # Update the weights of the model to minimize the loss value.\n",
        "        gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "      buffer = reservoir(buffer, buffer_size, X_train_choice, y_train_choice, get_logits(X_train_choice))\n",
        "      print(\"epoch:\", i, \"loss:\", loss_value, \"acc:\", empirical_predict(model, X_test_choice, y_test_choice))\n",
        "    \n",
        "  acc_list = [-1]*NUM_TASK\n",
        "  for learned_index in range(len(task_list)):\n",
        "    _, X_test_learned, _, y_test_learned = task_list[learned_index]\n",
        "    # print(X_test_learned)\n",
        "    acc_list[learned_index] = empirical_predict(model, np.array(X_test_learned), y_test_learned)\n",
        "  acc_task_list.append(acc_list)\n",
        "  print(\"acc of learned task:\", acc_list)\n",
        "  print(\"-------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFOqjDISAFn_",
        "outputId": "6025471e-9b52-4132-b80e-1cf41e2c6f6d"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TASK: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: tf.Tensor(0.78744286, shape=(), dtype=float32) acc: 0.44007576921107866\n",
            "acc of learned task: [0.44007576921107866, -1, -1, -1, -1]\n",
            "-------------------------------------------------\n",
            "TASK: 1\n",
            "epoch: 0 loss: tf.Tensor(8.630467, shape=(), dtype=float32) acc: 0.7649549768800195\n",
            "acc of learned task: [0.20314339835150771, 0.7649549768800195, -1, -1, -1]\n",
            "-------------------------------------------------\n",
            "TASK: 2\n",
            "epoch: 0 loss: tf.Tensor(4.3403835, shape=(), dtype=float32) acc: 0.7921635434412265\n",
            "acc of learned task: [0.18327957814979778, 0.7921635434412265, 0.7921635434412265, -1, -1]\n",
            "-------------------------------------------------\n",
            "TASK: 3\n",
            "epoch: 0 loss: tf.Tensor(9.137403, shape=(), dtype=float32) acc: 0.8154268129515654\n",
            "acc of learned task: [0.2126145497363436, 0.0, 0.0, 0.8154268129515654, -1]\n",
            "-------------------------------------------------\n",
            "TASK: 4\n",
            "epoch: 0 loss: tf.Tensor(9.514449, shape=(), dtype=float32) acc: 0.8355834136933462\n",
            "acc of learned task: [0.0, 0.6328060355317595, 0.6328060355317595, 0.0, 0.8355834136933462]\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DER"
      ],
      "metadata": {
        "id": "EPfR_aB8rrDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "acc_sequence = []\n",
        "LEEP_sequence = []\n",
        "\n",
        "# model = MLP_model(input_shape=len(X[0]))\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "for s in range(NUM_SEQUENCE):\n",
        "  model = MLP_model(input_shape=len(X[0]))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "  choose_class = []\n",
        "  acc_task_list = []\n",
        "\n",
        "  buffer = []\n",
        "\n",
        "  task_list = []\n",
        "\n",
        "  print(\"SEQUENCE:\", s)\n",
        "  LEEP_score = []\n",
        "  for t in range(NUM_TASK):\n",
        "    print(\"TASK:\", t)\n",
        "    #pick class\n",
        "    rand = random.randint(0, 7)\n",
        "    while rand in choose_class:\n",
        "      rand = random.randint(0, 7)\n",
        "    choose_class.append(rand)\n",
        "    pick_class = [rand]\n",
        "    count = 0\n",
        "    while count < NUM_CLASS - 1:\n",
        "      count =  count + 1\n",
        "      pick_class.append(pick_class[0]+count)\n",
        "    \n",
        "    print(pick_class)\n",
        "    \n",
        "    #pick data train\n",
        "    X_train_choice = []\n",
        "    y_train_choice = []\n",
        "    for i in range(len(X)):\n",
        "      if y[i] in pick_class:\n",
        "        X_train_choice.append(X[i])\n",
        "        y_train_choice.append(y[i])\n",
        "    \n",
        "    #pick data test\n",
        "    X_test_choice = []\n",
        "    y_test_choice = []\n",
        "    for i in range(len(X_test)):\n",
        "      if y_test_raw[i] in pick_class:\n",
        "        X_test_choice.append(X_test[i])\n",
        "        y_test_choice.append(y_test_raw[i])\n",
        "\n",
        "    task_list.append([X_train_choice, X_test_choice, y_train_choice, y_test_choice])\n",
        "\n",
        "    X_train_choice = np.array(X_train_choice)\n",
        "\n",
        "    # if t>0:\n",
        "      # LEEP_score.append(LEEP(y_train_choice, model(X_train_choice)))\n",
        "\n",
        "    y_train_choice =  tf.keras.utils.to_categorical(y_train_choice, num_classes = 10)\n",
        "\n",
        "    X_test_choice = np.array(X_test_choice)\n",
        "    # y_test_choice =  tf.keras.utils.to_categorical(y_test_choice, num_classes = 10)\n",
        "\n",
        "    #calculate LEEP score\n",
        "\n",
        "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.SGD()\n",
        "\n",
        "    for i in range(epochs):\n",
        "        iterations = len(X_train_choice)//batch_size\n",
        "        for j in range(iterations):\n",
        "          if len(buffer) > 0:\n",
        "            X_buffer, y_buffer, z_buffer = buffer[0], buffer[1], buffer[2]\n",
        "            X_buffer_batch, y_buffer_batch = batch_data(X_buffer, y_buffer, batch_size)\n",
        "            reg = np.linalg.norm(z_buffer-model(X_buffer))\n",
        "          else:\n",
        "            reg = 0\n",
        "          X_batch, y_batch = batch_data(X_train_choice, y_train_choice, batch_size)\n",
        "          with tf.GradientTape() as tape:\n",
        "              z_batch = get_logits(X_batch)\n",
        "              logits = model(X_batch)\n",
        "              # Compute the loss value for this batch.\n",
        "              loss_value = loss_fn(y_batch, logits) + alpha*reg\n",
        "\n",
        "          # Update the weights of the model to minimize the loss value.\n",
        "          gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "          optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "        buffer = reservoir(buffer, buffer_size, X_train_choice, y_train_choice, get_logits(X_train_choice))\n",
        "\n",
        "        _, acc = model.evaluate(X_test_choice, tf.keras.utils.to_categorical(y_test_choice, num_classes = 10))\n",
        "        print(\"epoch:\", i, \"loss:\", loss_value, \"acc:\", acc)\n",
        "      \n",
        "    acc_list = [-1]*NUM_TASK\n",
        "    for learned_index in range(len(task_list)):\n",
        "      _, X_test_learned, _, y_test_learned = task_list[learned_index]\n",
        "      # print(X_test_learned)\n",
        "      #acc_list[learned_index] = empirical_predict(model, np.array(X_test_learned), y_test_learned)\n",
        "      _, acc_list[learned_index] = model.evaluate(np.array(X_test_learned), tf.keras.utils.to_categorical(y_test_learned, num_classes = 10))\n",
        "    acc_task_list.append(acc_list)\n",
        "    print(\"acc of learned task:\", acc_list)\n",
        "    print(\"-------------------------------------------------\")\n",
        "  acc_sequence.append(np.mean(acc_task_list[-1]))\n",
        "  # LEEP_sequence.append(np.mean(LEEP_score))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "lxqQ8utPcpkv",
        "outputId": "4623e0e1-4033-4b64-ff7f-d0b8e2bfbc93"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEQUENCE: 0\n",
            "TASK: 0\n",
            "[6, 7, 8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-3b84573bf931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m           \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m               \u001b[0mz_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m               \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m               \u001b[0;31m# Compute the loss value for this batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \"\"\"\n\u001b[1;32m    458\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 459\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;31m# - mixed precision casting (autocast) is only applied to `inputs`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;31m#   not to any other argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_out_first_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJFy9srD7Oy0",
        "outputId": "9dba1126-2217-4ca8-d815-361df4cc195e"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17752818213775753,\n",
              " 0.2876280754804611,\n",
              " 0.14311457071453332,\n",
              " 0.2922462195158005,\n",
              " 0.1471982479095459,\n",
              " 0.20605331063270568,\n",
              " 0.24535101056098937,\n",
              " 0.20565402277279646,\n",
              " 0.21852719653397798,\n",
              " 0.22775341868400573]"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(LEEP_sequence, acc_sequence, marker='.', linestyle = 'None')\n",
        "# axis labels\n",
        "plt.xlabel('LEEP Score')\n",
        "plt.ylabel('Average Accuracy')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.savefig(\"10 Sequences - 5 Tasks - 3 Classes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Fv1sTq-OtWvB",
        "outputId": "e6b2da89-2d97-42b6-d6fd-2f2a424364a6"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.corrcoef(LEEP_sequence, acc_sequence)[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTX7A0LgkLug",
        "outputId": "992f7d5c-b1c3-424b-e25f-3407ce410e28"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.1390833706860988"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check"
      ],
      "metadata": {
        "id": "LrX5jer8rt0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "acc_sequence = []\n",
        "LEEP_sequence = []\n",
        "\n",
        "# model = MLP_model(input_shape=len(X[0]))\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "for s in range(NUM_SEQUENCE):\n",
        "  model = MLP_model(input_shape=len(X[0]))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "  get_logits = Model(inputs=model.input,\n",
        "                    outputs=model.get_layer(model.layers[-2].name).output)\n",
        "\n",
        "  choose_class = []\n",
        "  acc_task_list = []\n",
        "\n",
        "  buffer = []\n",
        "\n",
        "  task_list = []\n",
        "\n",
        "  print(\"SEQUENCE:\", s)\n",
        "  LEEP_score = []\n",
        "  for t in range(NUM_TASK):\n",
        "    print(\"TASK:\", t)\n",
        "    #pick class\n",
        "    rand = random.randint(0, 7)\n",
        "    while rand in choose_class:\n",
        "      rand = random.randint(0, 7)\n",
        "    choose_class.append(rand)\n",
        "    pick_class = [rand]\n",
        "    count = 0\n",
        "    while count < NUM_CLASS - 1:\n",
        "      count =  count + 1\n",
        "      pick_class.append(pick_class[0]+count)\n",
        "    \n",
        "    print(pick_class)\n",
        "    \n",
        "    #pick data train\n",
        "    X_train_choice = []\n",
        "    y_train_choice = []\n",
        "    for i in range(len(X)):\n",
        "      if y[i] in pick_class:\n",
        "        X_train_choice.append(X[i])\n",
        "        y_train_choice.append(y[i])\n",
        "    \n",
        "    #pick data test\n",
        "    X_test_choice = []\n",
        "    y_test_choice = []\n",
        "    for i in range(len(X_test)):\n",
        "      if y_test_raw[i] in pick_class:\n",
        "        X_test_choice.append(X_test[i])\n",
        "        y_test_choice.append(y_test_raw[i])\n",
        "\n",
        "    task_list.append([X_train_choice, X_test_choice, y_train_choice, y_test_choice])\n",
        "\n",
        "    X_train_choice = np.array(X_train_choice)\n",
        "\n",
        "    # if t>0:\n",
        "      # LEEP_score.append(LEEP(y_train_choice, model(X_train_choice)))\n",
        "\n",
        "    y_train_choice =  tf.keras.utils.to_categorical(y_train_choice, num_classes = 10)\n",
        "\n",
        "    X_test_choice = np.array(X_test_choice)\n",
        "    # y_test_choice =  tf.keras.utils.to_categorical(y_test_choice, num_classes = 10)\n",
        "\n",
        "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.SGD()\n",
        "\n",
        "    for i in range(epochs):\n",
        "        iterations = len(X_train_choice)//batch_size\n",
        "        for j in range(iterations):\n",
        "          if len(buffer) > 0:\n",
        "            X_buffer, y_buffer, z_buffer = buffer[0], buffer[1], buffer[2]\n",
        "            X_buffer_batch, y_buffer_batch = batch_data(X_buffer, y_buffer, batch_size)\n",
        "            reg = np.linalg.norm(z_buffer-get_logits(X_buffer))\n",
        "          else:\n",
        "            reg = 0\n",
        "          X_batch, y_batch = batch_data(X_train_choice, y_train_choice, batch_size)\n",
        "          with tf.GradientTape() as tape:\n",
        "              # z_batch = get_logits(X_batch)\n",
        "              logits = model(X_batch)\n",
        "              # Compute the loss value for this batch.\n",
        "              loss_value = lr*(loss_fn(y_batch, logits) + alpha*reg)\n",
        "\n",
        "          # Update the weights of the model to minimize the loss value.\n",
        "          gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "          optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "        buffer = reservoir(buffer, buffer_size, X_train_choice, y_train_choice, np.array(get_logits(X_train_choice)))\n",
        "        # print(np.array(get_logits(X_train_choice)))\n",
        "        # print(\"X:\", buffer[0])\n",
        "        # print(\"y:\", buffer[1])\n",
        "        # print(\"z:\", buffer[2])\n",
        "\n",
        "        _, acc = model.evaluate(X_test_choice, tf.keras.utils.to_categorical(y_test_choice, num_classes = 10))\n",
        "        print(\"epoch:\", i, \"loss:\", loss_value, \"acc:\", acc)\n",
        "      \n",
        "    acc_list = [-1]*NUM_TASK\n",
        "    for learned_index in range(len(task_list)):\n",
        "      _, X_test_learned, _, y_test_learned = task_list[learned_index]\n",
        "      # print(X_test_learned)\n",
        "      #acc_list[learned_index] = empirical_predict(model, np.array(X_test_learned), y_test_learned)\n",
        "      _, acc_list[learned_index] = model.evaluate(np.array(X_test_learned), tf.keras.utils.to_categorical(y_test_learned, num_classes = 10))\n",
        "    acc_task_list.append(acc_list)\n",
        "    print(\"acc of learned task:\", acc_list)\n",
        "    print(\"-------------------------------------------------\")\n",
        "  acc_sequence.append(np.mean(acc_task_list[-1]))\n",
        "  # LEEP_sequence.append(np.mean(LEEP_score))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9QfbtebeGz2s",
        "outputId": "028fe154-8a72-457e-fec7-8c5bf7dcd88a"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEQUENCE: 0\n",
            "TASK: 0\n",
            "[2, 3, 4]\n",
            "95/95 [==============================] - 1s 4ms/step - loss: 0.2871 - accuracy: 0.9580\n",
            "epoch: 0 loss: tf.Tensor(0.0027729773, shape=(), dtype=float32) acc: 0.9580026268959045\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.9630\n",
            "epoch: 1 loss: tf.Tensor(4.4690943, shape=(), dtype=float32) acc: 0.9629629850387573\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9676\n",
            "epoch: 2 loss: tf.Tensor(3.714212, shape=(), dtype=float32) acc: 0.9675925970077515\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9745\n",
            "epoch: 3 loss: tf.Tensor(3.023974, shape=(), dtype=float32) acc: 0.9745370149612427\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9752\n",
            "epoch: 4 loss: tf.Tensor(2.1842155, shape=(), dtype=float32) acc: 0.9751983880996704\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9759\n",
            "epoch: 5 loss: tf.Tensor(1.6701671, shape=(), dtype=float32) acc: 0.9758597612380981\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9769\n",
            "epoch: 6 loss: tf.Tensor(1.7093608, shape=(), dtype=float32) acc: 0.9768518805503845\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1361 - accuracy: 0.9762\n",
            "epoch: 7 loss: tf.Tensor(1.1393725, shape=(), dtype=float32) acc: 0.976190447807312\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9775\n",
            "epoch: 8 loss: tf.Tensor(1.2239081, shape=(), dtype=float32) acc: 0.9775132536888123\n",
            "95/95 [==============================] - 1s 7ms/step - loss: 0.1334 - accuracy: 0.9759\n",
            "epoch: 9 loss: tf.Tensor(0.9759136, shape=(), dtype=float32) acc: 0.9758597612380981\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9759\n",
            "epoch: 10 loss: tf.Tensor(0.7263572, shape=(), dtype=float32) acc: 0.9758597612380981\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9769\n",
            "epoch: 11 loss: tf.Tensor(0.45239225, shape=(), dtype=float32) acc: 0.9768518805503845\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9765\n",
            "epoch: 12 loss: tf.Tensor(0.56669396, shape=(), dtype=float32) acc: 0.9765211343765259\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9772\n",
            "epoch: 13 loss: tf.Tensor(0.2871952, shape=(), dtype=float32) acc: 0.9771825671195984\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9769\n",
            "epoch: 14 loss: tf.Tensor(0.26578122, shape=(), dtype=float32) acc: 0.9768518805503845\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9772\n",
            "epoch: 15 loss: tf.Tensor(0.39594358, shape=(), dtype=float32) acc: 0.9771825671195984\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9782\n",
            "epoch: 16 loss: tf.Tensor(0.1649871, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9778\n",
            "epoch: 17 loss: tf.Tensor(0.16798912, shape=(), dtype=float32) acc: 0.9778439402580261\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9778\n",
            "epoch: 18 loss: tf.Tensor(0.15470815, shape=(), dtype=float32) acc: 0.9778439402580261\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9782\n",
            "epoch: 19 loss: tf.Tensor(0.16911858, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9778\n",
            "epoch: 20 loss: tf.Tensor(0.13790174, shape=(), dtype=float32) acc: 0.9778439402580261\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9782\n",
            "epoch: 21 loss: tf.Tensor(0.16298757, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9778\n",
            "epoch: 22 loss: tf.Tensor(0.127983, shape=(), dtype=float32) acc: 0.9778439402580261\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9785\n",
            "epoch: 23 loss: tf.Tensor(0.10538674, shape=(), dtype=float32) acc: 0.9785053133964539\n",
            "95/95 [==============================] - 1s 6ms/step - loss: 0.1269 - accuracy: 0.9782\n",
            "epoch: 24 loss: tf.Tensor(0.12806465, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9782\n",
            "epoch: 25 loss: tf.Tensor(0.09968884, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9782\n",
            "epoch: 26 loss: tf.Tensor(0.106278986, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9782\n",
            "epoch: 27 loss: tf.Tensor(0.09714309, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9782\n",
            "epoch: 28 loss: tf.Tensor(0.110698655, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9782\n",
            "epoch: 29 loss: tf.Tensor(0.08192636, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9782\n",
            "epoch: 30 loss: tf.Tensor(0.094517, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9782\n",
            "epoch: 31 loss: tf.Tensor(0.07558443, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9782\n",
            "epoch: 32 loss: tf.Tensor(0.07714617, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9782\n",
            "epoch: 33 loss: tf.Tensor(0.079546764, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9782\n",
            "epoch: 34 loss: tf.Tensor(0.06678834, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9782\n",
            "epoch: 35 loss: tf.Tensor(0.08125599, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9782\n",
            "epoch: 36 loss: tf.Tensor(0.07021552, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9782\n",
            "epoch: 37 loss: tf.Tensor(0.06382373, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9782\n",
            "epoch: 38 loss: tf.Tensor(0.07327493, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9782\n",
            "epoch: 39 loss: tf.Tensor(0.09068162, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9782\n",
            "epoch: 40 loss: tf.Tensor(0.0920344, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9785\n",
            "epoch: 41 loss: tf.Tensor(0.05108108, shape=(), dtype=float32) acc: 0.9785053133964539\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9782\n",
            "epoch: 42 loss: tf.Tensor(0.05893856, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.9782\n",
            "epoch: 43 loss: tf.Tensor(0.06764817, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9782\n",
            "epoch: 44 loss: tf.Tensor(0.05084414, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9782\n",
            "epoch: 45 loss: tf.Tensor(0.05270094, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9782\n",
            "epoch: 46 loss: tf.Tensor(0.059892487, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9782\n",
            "epoch: 47 loss: tf.Tensor(0.05759534, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9782\n",
            "epoch: 48 loss: tf.Tensor(0.057967614, shape=(), dtype=float32) acc: 0.97817462682724\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9785\n",
            "epoch: 49 loss: tf.Tensor(0.058764357, shape=(), dtype=float32) acc: 0.9785053133964539\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9785\n",
            "acc of learned task: [0.9785053133964539, -1, -1, -1, -1]\n",
            "-------------------------------------------------\n",
            "TASK: 1\n",
            "[4, 5, 6]\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.9629\n",
            "epoch: 0 loss: tf.Tensor(14.322352, shape=(), dtype=float32) acc: 0.9629237055778503\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1645 - accuracy: 0.9718\n",
            "epoch: 1 loss: tf.Tensor(4.10717, shape=(), dtype=float32) acc: 0.9717513918876648\n",
            "89/89 [==============================] - 0s 5ms/step - loss: 0.1511 - accuracy: 0.9739\n",
            "epoch: 2 loss: tf.Tensor(2.45726, shape=(), dtype=float32) acc: 0.973870038986206\n",
            "89/89 [==============================] - 0s 5ms/step - loss: 0.1268 - accuracy: 0.9788\n",
            "epoch: 3 loss: tf.Tensor(2.1884072, shape=(), dtype=float32) acc: 0.9788135886192322\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9781\n",
            "epoch: 4 loss: tf.Tensor(1.5896702, shape=(), dtype=float32) acc: 0.9781073331832886\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9781\n",
            "epoch: 5 loss: tf.Tensor(1.7418453, shape=(), dtype=float32) acc: 0.9781073331832886\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9774\n",
            "epoch: 6 loss: tf.Tensor(1.070264, shape=(), dtype=float32) acc: 0.9774011373519897\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9802\n",
            "epoch: 7 loss: tf.Tensor(1.0358266, shape=(), dtype=float32) acc: 0.9802259802818298\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9795\n",
            "epoch: 8 loss: tf.Tensor(0.9930077, shape=(), dtype=float32) acc: 0.979519784450531\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9799\n",
            "epoch: 9 loss: tf.Tensor(0.9799616, shape=(), dtype=float32) acc: 0.9798728823661804\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9799\n",
            "epoch: 10 loss: tf.Tensor(0.48146278, shape=(), dtype=float32) acc: 0.9798728823661804\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9799\n",
            "epoch: 11 loss: tf.Tensor(0.31915033, shape=(), dtype=float32) acc: 0.9798728823661804\n",
            "89/89 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9795\n",
            "epoch: 12 loss: tf.Tensor(0.29571864, shape=(), dtype=float32) acc: 0.979519784450531\n",
            "89/89 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9802\n",
            "epoch: 13 loss: tf.Tensor(0.17638114, shape=(), dtype=float32) acc: 0.9802259802818298\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.9799\n",
            "epoch: 14 loss: tf.Tensor(0.16905423, shape=(), dtype=float32) acc: 0.9798728823661804\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9809\n",
            "epoch: 15 loss: tf.Tensor(0.19069174, shape=(), dtype=float32) acc: 0.9809321761131287\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9809\n",
            "epoch: 16 loss: tf.Tensor(0.14401677, shape=(), dtype=float32) acc: 0.9809321761131287\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9816\n",
            "epoch: 17 loss: tf.Tensor(0.13578436, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9802\n",
            "epoch: 18 loss: tf.Tensor(0.14515866, shape=(), dtype=float32) acc: 0.9802259802818298\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9809\n",
            "epoch: 19 loss: tf.Tensor(0.13134313, shape=(), dtype=float32) acc: 0.9809321761131287\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9809\n",
            "epoch: 20 loss: tf.Tensor(0.12105195, shape=(), dtype=float32) acc: 0.9809321761131287\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.9806\n",
            "epoch: 21 loss: tf.Tensor(0.09408442, shape=(), dtype=float32) acc: 0.9805790781974792\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9806\n",
            "epoch: 22 loss: tf.Tensor(0.095995225, shape=(), dtype=float32) acc: 0.9805790781974792\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9809\n",
            "epoch: 23 loss: tf.Tensor(0.07530698, shape=(), dtype=float32) acc: 0.9809321761131287\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9806\n",
            "epoch: 24 loss: tf.Tensor(0.11014487, shape=(), dtype=float32) acc: 0.9805790781974792\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9813\n",
            "epoch: 25 loss: tf.Tensor(0.103984796, shape=(), dtype=float32) acc: 0.9812853336334229\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9813\n",
            "epoch: 26 loss: tf.Tensor(0.1027469, shape=(), dtype=float32) acc: 0.9812853336334229\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9809\n",
            "epoch: 27 loss: tf.Tensor(0.09741721, shape=(), dtype=float32) acc: 0.9809321761131287\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9809\n",
            "epoch: 28 loss: tf.Tensor(0.08202437, shape=(), dtype=float32) acc: 0.9809321761131287\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9809\n",
            "epoch: 29 loss: tf.Tensor(0.06965485, shape=(), dtype=float32) acc: 0.9809321761131287\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9816\n",
            "epoch: 30 loss: tf.Tensor(0.098874316, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9813\n",
            "epoch: 31 loss: tf.Tensor(0.07374505, shape=(), dtype=float32) acc: 0.9812853336334229\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9820\n",
            "epoch: 32 loss: tf.Tensor(0.083395466, shape=(), dtype=float32) acc: 0.9819915294647217\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9816\n",
            "epoch: 33 loss: tf.Tensor(0.0785107, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9813\n",
            "epoch: 34 loss: tf.Tensor(0.10334016, shape=(), dtype=float32) acc: 0.9812853336334229\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9816\n",
            "epoch: 35 loss: tf.Tensor(0.07260877, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9813\n",
            "epoch: 36 loss: tf.Tensor(0.06043697, shape=(), dtype=float32) acc: 0.9812853336334229\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9816\n",
            "epoch: 37 loss: tf.Tensor(0.06730729, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9820\n",
            "epoch: 38 loss: tf.Tensor(0.068200506, shape=(), dtype=float32) acc: 0.9819915294647217\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9820\n",
            "epoch: 39 loss: tf.Tensor(0.054468703, shape=(), dtype=float32) acc: 0.9819915294647217\n",
            "89/89 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.9816\n",
            "epoch: 40 loss: tf.Tensor(0.06306294, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9816\n",
            "epoch: 41 loss: tf.Tensor(0.055969764, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9823\n",
            "epoch: 42 loss: tf.Tensor(0.059099846, shape=(), dtype=float32) acc: 0.9823446273803711\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9823\n",
            "epoch: 43 loss: tf.Tensor(0.048528034, shape=(), dtype=float32) acc: 0.9823446273803711\n",
            "89/89 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9816\n",
            "epoch: 44 loss: tf.Tensor(0.06048247, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9816\n",
            "epoch: 45 loss: tf.Tensor(0.04594643, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9816\n",
            "epoch: 46 loss: tf.Tensor(0.05433675, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9816\n",
            "epoch: 47 loss: tf.Tensor(0.06362457, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 1s 7ms/step - loss: 0.1189 - accuracy: 0.9816\n",
            "epoch: 48 loss: tf.Tensor(0.062982865, shape=(), dtype=float32) acc: 0.9816384315490723\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9813\n",
            "epoch: 49 loss: tf.Tensor(0.041682392, shape=(), dtype=float32) acc: 0.9812853336334229\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 22.0372 - accuracy: 0.3267\n",
            "89/89 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9813\n",
            "acc of learned task: [0.32671958208084106, 0.9812853336334229, -1, -1, -1]\n",
            "-------------------------------------------------\n",
            "TASK: 2\n",
            "[7, 8, 9]\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.9412\n",
            "epoch: 0 loss: tf.Tensor(21.268707, shape=(), dtype=float32) acc: 0.9412155151367188\n",
            "95/95 [==============================] - 0s 5ms/step - loss: 0.2402 - accuracy: 0.9469\n",
            "epoch: 1 loss: tf.Tensor(3.9139237, shape=(), dtype=float32) acc: 0.9468615055084229\n",
            "95/95 [==============================] - 0s 5ms/step - loss: 0.1786 - accuracy: 0.9595\n",
            "epoch: 2 loss: tf.Tensor(2.3826306, shape=(), dtype=float32) acc: 0.9594818949699402\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1973 - accuracy: 0.9575\n",
            "epoch: 3 loss: tf.Tensor(2.0337307, shape=(), dtype=float32) acc: 0.9574891924858093\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9648\n",
            "epoch: 4 loss: tf.Tensor(1.6206708, shape=(), dtype=float32) acc: 0.9647957682609558\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9641\n",
            "epoch: 5 loss: tf.Tensor(1.3842528, shape=(), dtype=float32) acc: 0.9641315340995789\n",
            "95/95 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.9665\n",
            "epoch: 6 loss: tf.Tensor(1.1180507, shape=(), dtype=float32) acc: 0.9664563536643982\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9671\n",
            "epoch: 7 loss: tf.Tensor(1.2313553, shape=(), dtype=float32) acc: 0.9671205282211304\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9691\n",
            "epoch: 8 loss: tf.Tensor(1.1369088, shape=(), dtype=float32) acc: 0.9691132307052612\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9694\n",
            "epoch: 9 loss: tf.Tensor(0.8023723, shape=(), dtype=float32) acc: 0.9694453477859497\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9708\n",
            "epoch: 10 loss: tf.Tensor(0.8216191, shape=(), dtype=float32) acc: 0.9707738161087036\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9694\n",
            "epoch: 11 loss: tf.Tensor(0.776463, shape=(), dtype=float32) acc: 0.9694453477859497\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9721\n",
            "epoch: 12 loss: tf.Tensor(0.69399387, shape=(), dtype=float32) acc: 0.9721022844314575\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9704\n",
            "epoch: 13 loss: tf.Tensor(0.56158227, shape=(), dtype=float32) acc: 0.9704416990280151\n",
            "95/95 [==============================] - 1s 6ms/step - loss: 0.1148 - accuracy: 0.9721\n",
            "epoch: 14 loss: tf.Tensor(0.5377828, shape=(), dtype=float32) acc: 0.9721022844314575\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9721\n",
            "epoch: 15 loss: tf.Tensor(0.525964, shape=(), dtype=float32) acc: 0.9721022844314575\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9711\n",
            "epoch: 16 loss: tf.Tensor(0.5237499, shape=(), dtype=float32) acc: 0.9711059331893921\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9721\n",
            "epoch: 17 loss: tf.Tensor(0.32952735, shape=(), dtype=float32) acc: 0.9721022844314575\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9714\n",
            "epoch: 18 loss: tf.Tensor(0.3606077, shape=(), dtype=float32) acc: 0.9714380502700806\n",
            "95/95 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9721\n",
            "epoch: 19 loss: tf.Tensor(0.4643754, shape=(), dtype=float32) acc: 0.9721022844314575\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9718\n",
            "epoch: 20 loss: tf.Tensor(0.38005707, shape=(), dtype=float32) acc: 0.971770167350769\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9728\n",
            "epoch: 21 loss: tf.Tensor(0.35499513, shape=(), dtype=float32) acc: 0.9727665185928345\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9724\n",
            "epoch: 22 loss: tf.Tensor(0.28679192, shape=(), dtype=float32) acc: 0.972434401512146\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9731\n",
            "epoch: 23 loss: tf.Tensor(0.31344113, shape=(), dtype=float32) acc: 0.973098635673523\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9724\n",
            "epoch: 24 loss: tf.Tensor(0.2712573, shape=(), dtype=float32) acc: 0.972434401512146\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9724\n",
            "epoch: 25 loss: tf.Tensor(0.21791649, shape=(), dtype=float32) acc: 0.972434401512146\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9724\n",
            "epoch: 26 loss: tf.Tensor(0.23121497, shape=(), dtype=float32) acc: 0.972434401512146\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9721\n",
            "epoch: 27 loss: tf.Tensor(0.24887869, shape=(), dtype=float32) acc: 0.9721022844314575\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9734\n",
            "epoch: 28 loss: tf.Tensor(0.2779402, shape=(), dtype=float32) acc: 0.9734307527542114\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9731\n",
            "epoch: 29 loss: tf.Tensor(0.23129094, shape=(), dtype=float32) acc: 0.973098635673523\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.9724\n",
            "epoch: 30 loss: tf.Tensor(0.26270765, shape=(), dtype=float32) acc: 0.972434401512146\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9721\n",
            "epoch: 31 loss: tf.Tensor(0.20478337, shape=(), dtype=float32) acc: 0.9721022844314575\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9724\n",
            "epoch: 32 loss: tf.Tensor(0.18101588, shape=(), dtype=float32) acc: 0.972434401512146\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9724\n",
            "epoch: 33 loss: tf.Tensor(0.14766502, shape=(), dtype=float32) acc: 0.972434401512146\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9728\n",
            "epoch: 34 loss: tf.Tensor(0.15291414, shape=(), dtype=float32) acc: 0.9727665185928345\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9728\n",
            "epoch: 35 loss: tf.Tensor(0.16872786, shape=(), dtype=float32) acc: 0.9727665185928345\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-0f0b42b0f9d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m               \u001b[0;31m# z_batch = get_logits(X_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m               \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m               \u001b[0;31m# Compute the loss value for this batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m               \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \"\"\"\n\u001b[1;32m    458\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 459\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/core/dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    219\u001b[0m             self.kernel, ids, weights, combiner='sum')\n\u001b[1;32m    220\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3712\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3713\u001b[0m         return gen_math_ops.mat_mul(\n\u001b[0;32m-> 3714\u001b[0;31m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   3715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6013\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   6014\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6015\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   6016\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6017\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_sequence"
      ],
      "metadata": {
        "id": "j6DCISKVh-81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "acc_sequence = []\n",
        "LEEP_sequence = []\n",
        "\n",
        "# model = MLP_model(input_shape=len(X[0]))\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "for s in range(NUM_SEQUENCE):\n",
        "  model = Transfer_model()\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "  get_logits = Model(inputs=model.input,\n",
        "                    outputs=model.get_layer(model.layers[-2].name).output)\n",
        "\n",
        "  choose_class = []\n",
        "  acc_task_list = []\n",
        "\n",
        "  buffer = []\n",
        "\n",
        "  task_list = []\n",
        "\n",
        "  print(\"SEQUENCE:\", s)\n",
        "  LEEP_score = []\n",
        "  for t in range(NUM_TASK):\n",
        "    print(\"TASK:\", t)\n",
        "    #pick class\n",
        "    rand = random.randint(0, 7)\n",
        "    while rand in choose_class:\n",
        "      rand = random.randint(0, 7)\n",
        "    choose_class.append(rand)\n",
        "    pick_class = [rand]\n",
        "    count = 0\n",
        "    while count < NUM_CLASS - 1:\n",
        "      count =  count + 1\n",
        "      pick_class.append(pick_class[0]+count)\n",
        "    \n",
        "    print(pick_class)\n",
        "    \n",
        "    #pick data train\n",
        "    X_train_choice = []\n",
        "    y_train_choice = []\n",
        "    for i in range(len(X)):\n",
        "      if y[i] in pick_class:\n",
        "        X_train_choice.append(X[i].reshape(28, 28))\n",
        "        y_train_choice.append(y[i])\n",
        "    \n",
        "    #pick data test\n",
        "    X_test_choice = []\n",
        "    y_test_choice = []\n",
        "    for i in range(len(X_test)):\n",
        "      if y_test_raw[i] in pick_class:\n",
        "        X_test_choice.append(X_test[i].reshape(28, 28))\n",
        "        y_test_choice.append(y_test_raw[i])\n",
        "\n",
        "    task_list.append([X_train_choice, X_test_choice, y_train_choice, y_test_choice])\n",
        "\n",
        "    X_train_choice = np.array(X_train_choice)\n",
        "\n",
        "    # if t>0:\n",
        "      # LEEP_score.append(LEEP(y_train_choice, model(X_train_choice)))\n",
        "\n",
        "    y_train_choice =  tf.keras.utils.to_categorical(y_train_choice, num_classes = 10)\n",
        "\n",
        "    X_test_choice = np.array(X_test_choice)\n",
        "    # y_test_choice =  tf.keras.utils.to_categorical(y_test_choice, num_classes = 10)\n",
        "\n",
        "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.SGD()\n",
        "\n",
        "    for i in range(epochs):\n",
        "        iterations = len(X_train_choice)//batch_size\n",
        "        for j in range(iterations):\n",
        "          if len(buffer) > 0:\n",
        "            X_buffer, y_buffer, z_buffer = buffer[0], buffer[1], buffer[2]\n",
        "            X_buffer_batch, y_buffer_batch = batch_data(X_buffer, y_buffer, batch_size)\n",
        "            reg = np.linalg.norm(z_buffer-model(X_buffer))\n",
        "          else:\n",
        "            reg = 0\n",
        "          # X_aug, y_aug = \n",
        "          X_batch, y_batch = batch_data(X_train_choice, y_train_choice, batch_size)\n",
        "          with tf.GradientTape() as tape:\n",
        "              logits = model(X_batch)\n",
        "              # Compute the loss value for this batch.\n",
        "              loss_value = lr*(loss_fn(y_batch, logits) + alpha*reg)\n",
        "\n",
        "          # Update the weights of the model to minimize the loss value.\n",
        "          gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "          optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "        buffer = reservoir(buffer, buffer_size, X_train_choice, y_train_choice, get_logits(X_train_choice))\n",
        "\n",
        "        _, acc = model.evaluate(X_test_choice, tf.keras.utils.to_categorical(y_test_choice, num_classes = 10))\n",
        "        print(\"epoch:\", i, \"loss:\", loss_value, \"acc:\", acc)\n",
        "      \n",
        "    acc_list = [-1]*NUM_TASK\n",
        "    for learned_index in range(len(task_list)):\n",
        "      _, X_test_learned, _, y_test_learned = task_list[learned_index]\n",
        "      # print(X_test_learned)\n",
        "      #acc_list[learned_index] = empirical_predict(model, np.array(X_test_learned), y_test_learned)\n",
        "      _, acc_list[learned_index] = model.evaluate(np.array(X_test_learned), tf.keras.utils.to_categorical(y_test_learned, num_classes = 10))\n",
        "    acc_task_list.append(acc_list)\n",
        "    print(\"acc of learned task:\", acc_list)\n",
        "    print(\"-------------------------------------------------\")\n",
        "  acc_sequence.append(np.mean(acc_task_list[-1]))\n",
        "  # LEEP_sequence.append(np.mean(LEEP_score))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "Wx_FiI5JOcuE",
        "outputId": "ace52734-a8f1-48ba-8943-e21f2a15455d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-fcca1559405b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_SEQUENCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransfer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-4f886c4a2c3f>\u001b[0m in \u001b[0;36mTransfer_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpretrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'x' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wgd9RyjsOnUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}